import torch, imagen_pytorch
import os, sys, csv, argparse, configparser


from tqdm import trange
from random import random, randint, shuffle
from torchvision import transforms
from pathlib import Path
from torch.utils import data
from PIL import Image
from imagen_pytorch import Unet, Imagen, ImagenTrainer

EXTS = ['jpg', 'jpeg', 'png']



class CustomLabeledDataset(data.Dataset):
    # Given a folder of images and a csv, returns a dataset of automatically generated (image, label) pairs.
    # Image filenames are used as the key lookup into the csv file.
    # The csv file should be formatted as 'filename,label1,label2,...' with as many labels as desired.
    # Description is generated by randomly concatenating labels.
    # Labels can contain anything except ',' and can be as long as you want. '\n' will get stripped out.
    def __init__(self, folder, image_size, csv_path='' ):
        super().__init__()
        self.folder = folder
        self.image_size = image_size
        self.paths = [p for ext in EXTS for p in Path(f'{folder}').glob(f'**/*.{ext}')]
        assert len(self.paths) > 0, f'No images were found in {folder} for training'
        if csv_path != '':
            with open(csv_path, 'rt') as fp:
                lines = [x.split(',') for x in fp.readlines()]
                self.texts = {x[0]: x[1:] for x in lines}

        self.transform = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.paths)

    def sanitize(self, t):
        replacements = {
            '\n': ' ',
        }
        
        for k, v in replacements.items():
            t = t.replace(k, v)
            
        return t
    
    # Returns a dict with 'txt' and 'img' keys.
    def __getitem__(self, index):
        # Retrieve image
        img_path = self.paths[index]
        img = self.transform(Image.open(img_path).convert("RGB")).to(device)
        if config.getboolean('Default', 'conditional'):
            img_filename = Path(img_path).stem

            assert img_filename in self.texts, f'Image {img_filename} not found in {csv_path}'

            # Get the labels for this image
            all_labels = self.texts[img_filename]

            # Generate the text to be used for training by randomly shuffling the labels
            # and joining with a space
            shuffle(all_labels)
            generated_full_description = ' '.join(all_labels)
            generated_full_description = self.sanitize(generated_full_description)

            
            return {
                'img': img,
                'txt': generated_full_description,
            }
        else:
            return { 'img': img }

def train(trainer):
    
    print('Loading training data')
    
    if config.getboolean('Default', 'conditional'):
        dataset = CustomLabeledDataset(
            folder=input_folder,
            csv_path=csv_path,
            image_size=config.getint('Default', 'training_image_size')
        )
    else:
        dataset = CustomLabeledDataset(
            folder=input_folder,
            image_size=config.getint('Default', 'training_image_size')
        )
        
    bar = trange(config.getint('Default', 'train_steps'))
    dataloader = batch_loader(dataset, batch_size=config.getint('Default', 'batch_size'), shuffle=True)
    print(f'Starting from step {int(trainer.step.item())}')
    try:
        # feed images into imagen, training each unet in the cascade
        for it in bar:
            loss_vals = []

            for i in (1, 2):
                batch = next(dataloader)
                images = batch['img']
                if config.getboolean('Default', 'conditional'):
                    texts = batch['txt']
                    loss = trainer(
                        images,
                        texts = texts,
                        unet_number = i,
                        max_batch_size = config.getint('Default', 'micro_batch_size'))
                else:
                    loss = trainer(
                        images,
                        unet_number = i,
                        max_batch_size = config.getint('Default', 'micro_batch_size'))
                loss_vals.append(loss)
                trainer.update(unet_number = i)

            bar.set_postfix(unet1=loss_vals[0], unet2=loss_vals[1])

            if (it + 1) % config.getint('Default', 'quicksave_every') == 0:
                trainer.save(os.path.join(save_dir, config['Default']['checkpoint_name']))
            if (it + 1) % config.getint('Default', 'checkpoint_every') == 0:
                total_it = int(trainer.step.item())
                trainer.save(os.path.join(save_dir, f'{args.model}_{total_it}.pth'))
    except KeyboardInterrupt:
        trainer.save(os.path.join(save_dir, f'{args.model}_interrupted.pth'))
        print("Caught Interrupt. If you want to use the training steps done before stopping, rename checkpoint_interrupted.pth")
        exit(1)

    total_it = int(trainer.step.item())
    trainer.save(os.path.join(save_dir, f'{args.model}_{total_it}.pth'))
    exit(0)

def sample(trainer):
    if config.getboolean('Default', 'conditional'):
        sample_texts = [args.prompt]
        images = trainer.sample(
            texts = sample_texts,
            batch_size = args.batch_samples,
            return_all_unet_outputs = False,
            return_pil_images = True, 
            cond_scale = 2.)


        for text in sample_texts:
            text_prompt_tracker = 0
            for image in images:
                image.save(text+str(text_prompt_tracker)+".png")
                text_prompt_tracker += 1

    else:
        images = trainer.sample(
            batch_size = args.batch_samples,
            return_all_unet_outputs = False,
            return_pil_images = True, 
            cond_scale = 2.)

        batch_tracker = 0
        for image in images:
            image.save(str(batch_tracker)+".png")
            batch_tracker += 1
    print("Saved images in output directory "+output_folder)

def batch_loader(data, batch_size, shuffle = True):
    from random import shuffle as do_shuffle
    
    indices = list(range(len(data)))

    while True:
        if shuffle:
            do_shuffle(indices)
        for i in range(0, len(indices), batch_size):
            # Drop the last batch if it's not the full batch size
            if i + batch_size > len(indices):
                break

            batch_indices = indices[i:i+batch_size]
            batch = [data[x] for x in batch_indices]

            images = torch.stack([x['img'] for x in batch])

            if config.getboolean('Default', 'conditional'):
                texts = [x['txt'] for x in batch]

                #yield batch
                yield {
                    'txt': texts,
                    'img': images,
                }
            else:

                yield {
                    'img': images,
                }

def arguments():
    parser = argparse.ArgumentParser(
    description='''
    Create, train, and sample Imagen models.
    
    If creating a new model with text descriptions or tags, use --init-conditional.
    If creating a model with only images, use --init-unconditional.
    
    See example.config for additional configuration information.
    ''')
# Required: Name of Model and Config file (ex: 'example' := example.pt and example.config)
    parser.add_argument('model', 
        default='mymodel',
        help='name of model and config file to use'
        )

    parser.add_argument('-a', '--action', 
        choices=['train', 'sample'],
        default='train',
        help='train or sample Imagen model (default: train)'
        )

    parser.add_argument('-p','--prompt',
        help='text prompt for sampling conditional models'
        )

    parser.add_argument('-n', '--number-samples',
        dest='batch_samples',
        type=int,
        help='number of samples to generate (nb: this will impact vRAM usage)')
        
    parser.add_argument('--cpu',
        action='store_true',
        help='use cpu for training or sampling (default: cuda)'
        )
    
    parser.add_argument('--force',
        action='store_true',
        help='force overwrite of config and model files'
        )

    # Optional: Initialize new model and config file? 
    parser.add_argument('--init-conditional',
        dest='icond',
        action='store_true',
        help='initialize a new conditional model and config file with the given name'
        )

    parser.add_argument('--init-unconditional',
        dest='iucond',
        action='store_true',
        help='initialize a new unconditional model and config file with the given name'
        )


    return parser.parse_args()

def initialize_files():
    config = configparser.ConfigParser()
    config['Default'] = {
        'quicksave_every':1000,
        'checkpoint_every':10000,
        'train_steps':100000,
        'micro_batch_size':4,
        'batch_size':32,
        'training_image_size':256,
        'checkpoint_name':args.model+"_latest.pth"
    }
    config['FilePaths'] = {
        'save_dir':args.model+"_checkpoints",
        'input_folder':args.model+"_images",
        'output_folder':args.model+"_samples",
    }
    if args.icond:
        config['Default']['conditional']="True"
        config['FilePaths']['csv_path']="\""+args.model+".csv\""
        config['Unet1'] = {
            'dim':128,
            'cond_dim':512,
            'dim_mults':'1, 2, 4, 8',
            'num_resnet_blocks':3,
            'use_linear_attn':False,
            'layer_attns':'False, True, True, True',
            'layer_cross_attns':'False, True, True, True'
        }
        config['Unet2'] = {
            'dim':128,
            'cond_dim':512,
            'dim_mults':'1, 2, 4, 8',
            'num_resnet_blocks':'2, 4, 8, 8',
            'use_linear_attn':False,
            'layer_attns':'False, False, False, True',
            'layer_cross_attns':'False, False, False, True'
        }
    else:
        config['Default']['conditional']="False"
        config['Unet1'] = {
            'dim':128,
            'cond_dim':512,
            'dim_mults':'1, 2, 4',
            'num_resnet_blocks':3,
            'use_linear_attn':False,
            'layer_attns':'False, True, True',
            'layer_cross_attns':'False, True, True'
        }
        config['Unet2'] = {
            'dim':128,
            'cond_dim':512,
            'dim_mults':'1, 2, 4',
            'num_resnet_blocks':'2, 4, 8',
            'use_linear_attn':False,
            'layer_attns':'False, False, True',
            'layer_cross_attns':'False, False, True'
        }

    with open(args.model+'.config', 'w') as configfile:
        config.write(configfile)

    if args.icond:
        print("Created conditional model and config with the name "+args.model)
    else:
        print("Created unconditional model and config file with the name "+args.model)

args = arguments()

device = torch.device('cpu') if args.cpu else torch.device('cuda:0')

# Hacks to add imagen repo to the path
imagen_path = os.path.expanduser('imagen-pytorch/')
sys.path.append(imagen_path)



if args.icond or args.iucond:
    if os.path.exists(args.model+".config"):
        print("Model and config already exist. Use --force to force overwrite")
        if args.force:
            print("Caught force flag, overwriting...")
            initialize_files()
            exit(0)
        else:
            exit(1)
    else:
        initialize_files()
    exit(0)

print("Loading config file "+args.model+".config...")

config = configparser.ConfigParser()
config.read(args.model+".config")

save_dir = os.path.expanduser(config['FilePaths']['save_dir'])
input_folder = os.path.expanduser(config['FilePaths']['input_folder'])
output_folder = os.path.expanduser(config['FilePaths']['output_folder'])
if config.getboolean('Default', 'conditional'):
    csv_path = os.path.expanduser(config['FilePaths']['csv_path'])


print("Constructing model...")

unet1 = Unet(
    dim = config.getint('Unet1','dim'),
    cond_dim = config.getint('Unet1','cond_dim'),
    dim_mults = tuple(map(int, config['Unet1']['dim_mults'].split(', '))),
    use_linear_attn = config.getboolean('Unet1', 'use_linear_attn'),
    num_resnet_blocks = config.getint('Unet1','num_resnet_blocks'),
    layer_attns = tuple(map(bool, config['Unet1']['layer_attns'].split(', '))),
    layer_cross_attns = tuple(map(bool, config['Unet1']['layer_cross_attns'].split(', ')))
).to(device)

unet2 = Unet(
    dim = config.getint('Unet2','dim'),
    cond_dim = config.getint('Unet2','cond_dim'),
    dim_mults = tuple(map(int, config['Unet2']['dim_mults'].split(', '))),
    use_linear_attn = config.getboolean('Unet2', 'use_linear_attn'),
    num_resnet_blocks = tuple(map(int, config['Unet1']['num_resnet_blocks'].split(', '))),
    layer_attns = tuple(map(bool, config['Unet1']['layer_attns'].split(', '))),
    layer_cross_attns = tuple(map(bool, config['Unet1']['layer_cross_attns'].split(', '))),
).to(device)



# imagen, which contains the unets above (base unet and super resoluting ones)

imagen = Imagen(
    condition_on_text = config.getboolean('Default', 'conditional'),
    unets = (unet1, unet2),
    image_sizes = (64, config.getint('Default', 'training_image_size')),
    timesteps = 1000,
    cond_drop_prob = 0.5
).to(device)


# wrap imagen with the trainer class

trainer = ImagenTrainer(imagen)

# Load checkpoint

print("Attempting to load model...")
checkpoint_path = os.path.join(save_dir, config['Default']['checkpoint_name'])
if os.path.exists(checkpoint_path):
    print("Loading Model")
    _ = trainer.load(checkpoint_path, only_model = False, strict = False)
else:
    print("No existing checkpoint found, sampling will produce noise")

if args.action == 'train':
    train(trainer)

if args.action == 'sample':
    sample(trainer)

print("No action or initialize arguments given. Please see help and annoted config file for more details.")