import torch
import os
import sys
import imagen_pytorch

from tqdm import trange
from random import random, randint, shuffle
from torchvision import transforms
from pathlib import Path
from torch.utils import data
from PIL import Image
from imagen_pytorch import Unet, Imagen, ImagenTrainer

### VARIABLES ###
EXTS = ['jpg', 'jpeg', 'png']
quicksave_every = 1000
checkpoint_every = 10000
train_steps = 120000
micro_batch_size = 4
batch_size = 8
training_image_size = 256


### PATHS ###
save_dir = os.path.expanduser("<OUTPUT_DIRECTORY>")
input_folder = os.path.expanduser(f"<INPUT_DIRECTORY>")
csv_path = os.path.expanduser(f"<FEATURE_CSV>")




class CustomLabeledDataset(data.Dataset):
    # Given a folder of images and a csv, returns a dataset of automatically generated (image, label) pairs.
    # Image filenames are used as the key lookup into the csv file.
    # The csv file should be formatted as 'filename,label1,label2,...' with as many labels as desired.
    # Description is generated by randomly concatenating labels.
    # Labels can contain anything except ',' and can be as long as you want. '\n' will get stripped out.
    def __init__(self, folder, csv_path, image_size):
        super().__init__()
        self.folder = folder
        self.image_size = image_size
        self.paths = [p for ext in EXTS for p in Path(f'{folder}').glob(f'**/*.{ext}')]
        assert len(self.paths) > 0, f'No images were found in {folder} for training'
        
        with open(csv_path, 'rt') as fp:
            lines = [x.split(',') for x in fp.readlines()]
            self.texts = {x[0]: x[1:] for x in lines}

        self.transform = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.paths)

    def sanitize(self, t):
        replacements = {
            '\n': ' ',
        }
        
        for k, v in replacements.items():
            t = t.replace(k, v)
            
        return t
    
    # Returns a dict with 'txt' and 'img' keys.
    def __getitem__(self, index):
        img_path = self.paths[index]
        img_filename = Path(img_path).stem
        assert img_filename in self.texts, f'Image {img_filename} not found in {csv_path}'

        # Get the labels for this image
        all_labels = self.texts[img_filename]

        # Generate the text to be used for training by randomly shuffling the labels
        # and joining with a space
        shuffle(all_labels)
        generated_full_description = ' '.join(all_labels)
        generated_full_description = self.sanitize(generated_full_description)

        # Retrieve image
        img = self.transform(Image.open(img_path).convert("RGB")).to(device)
        return {
            'img': img,
            'txt': generated_full_description,
        }


def batch_loader(data, batch_size, shuffle = True):
    from random import shuffle as do_shuffle
    
    indices = list(range(len(data)))

    while True:
        if shuffle:
            do_shuffle(indices)
        for i in range(0, len(indices), batch_size):
            # Drop the last batch if it's not the full batch size
            if i + batch_size > len(indices):
                break

            batch_indices = indices[i:i+batch_size]
            batch = [data[x] for x in batch_indices]

            texts = [x['txt'] for x in batch]

            images = torch.stack([x['img'] for x in batch])


            #yield batch
            yield {
                'txt': texts,
                'img': images,
            }




use_cpu = False
device = torch.device('cpu') if use_cpu else torch.device('cuda:0')


dataset = CustomLabeledDataset(
    folder=input_folder,
    csv_path=csv_path,
    image_size=training_image_size
)


# Hacks to add imagen repo to the path
imagen_path = os.path.expanduser('imagen-pytorch/')
sys.path.append(imagen_path)

print("Constructing model...")
# unet for imagen

unet1 = Unet(
    dim = 32,
    cond_dim = 512,
    dim_mults = (1, 2, 4, 8),
    use_linear_attn = False,
    num_resnet_blocks = 3,
    layer_attns = (False, True, True, True),
).to(device)

unet2 = Unet(
    dim = 32,
    cond_dim = 512,
    dim_mults = (1, 2, 4, 8),
    use_linear_attn = False,
    num_resnet_blocks = (2, 4, 8, 8),
    layer_attns = (False, False, False, True),
    layer_cross_attns = (False, False, False, True)
).to(device)



# imagen, which contains the unets above (base unet and super resoluting ones)

imagen = Imagen(
    unets = (unet1, unet2),
    text_encoder_name = 't5-3b',
    image_sizes = (64, 256),
    beta_schedules = ('cosine', 'linear'),
    timesteps = 1000,
    cond_drop_prob = 0.5
).to(device)


# wrap imagen with the trainer class

trainer = ImagenTrainer(imagen)

# Load checkpoint

print("Loading model...")
checkpoint_name = "checkpoint_latest.pth"
# _ = trainer.load(os.path.join("../content/Imagen-pytorch", "imagen-pytorch.pt"), only_model = False)
_ = trainer.load(os.path.join(save_dir, checkpoint_name), only_model = False)

print(f'Starting from step {int(trainer.step.item())}')

print('Loading training data')


bar = trange(train_steps)
dataloader = batch_loader(dataset, batch_size=batch_size, shuffle=True)


# feed images into imagen, training each unet in the cascade



for it in bar:
    loss_vals = []

    for i in (1, 2):
        total_loss = 0.
        batch = next(dataloader)
        images = batch['img']
        texts = batch['txt']
        loss = trainer(
            images,
            texts = texts,
            unet_number = i,
            max_batch_size = micro_batch_size)
        loss_vals.append(loss)
        trainer.update(unet_number = i)

    bar.set_postfix(unet1=loss_vals[0], unet2=loss_vals[1])

    if (it + 1) % quicksave_every == 0:
        trainer.save(os.path.join(save_dir, 'checkpoint_latest.pth'))
    if (it + 1) % checkpoint_every == 0:
        total_it = int(trainer.step.item())
        trainer.save(os.path.join(save_dir, f'checkpoint_{total_it}.pth'))

# do the above for many many many many steps

total_it = int(trainer.step.item())
trainer.save(os.path.join(save_dir, f'checkpoint_{total_it}.pth'))
